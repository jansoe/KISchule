{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_jan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jansoe/KISchule/blob/main/A1_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOjzb42yrtEF"
      },
      "source": [
        "# 1. Einführung in das Thema *Bilddaten*\n",
        "\n",
        "Diese Woche beginnen wir, uns mit dem Programmieren die Hände schmutzig zu machen. Wir lernen die Grundlagen der Bildverarbeitung sowie den Umgang mit Dateien und Ordnern in Google Colab und Google Drive.\n",
        "\n",
        "Das Verfahren ist wie gehabt:\n",
        "- Erstellen Sie eine Kopie dieses Notebooks in ihrem Google Drive (vorgeschlagene Umbenennung: \"A1 - Vorname, Nachname\")\n",
        "- Editieren Sie die Text- und Codezellen.\n",
        "- Teilen Sie Ihr Notebook mit uns \n",
        "\n",
        "---\n",
        "**Anmerkungen**\n",
        "\n",
        "Sollten Sie bei der Bearbeitung der Aufgaben auf Probleme stoßen, nutzen Sie bitte zunächst die Kommentarfunktion von Colab, um Ihre Fragen möglichst konkret in Ihrem Notebook zu hinterlegen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDgOUkAQrmpq"
      },
      "source": [
        "## 1.0 Herunterladen und Verwalten von Bilddateien\n",
        "Da das Colab-Notebook auf einem Server läuft, können Sie nicht direkt auf Bilder zugreifen, die auf Ihrem Rechner gespeichert sind. Hierzu muss der Umweg über Ihr Google-Drive genommen werden. Dies haben Sie bereits im Bewerbungsformular kennengelernt. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XSFopvIwMy9"
      },
      "source": [
        "from google.colab import drive # Googles Python-Modul für Drive-Interaktion\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6GKSvJvwxIQ"
      },
      "source": [
        "Sie können nun unter dem Pfad `/content/drive/My Drive` auf Ihren Cloudspeicher zugreifen.\n",
        "\n",
        "Mit einem vorgestellten Ausrufezeichen können in den Code-Zellen des Notebooks auch Linux-Konsolenbefehle ausgeführt werden. So zum Beispiel der Befehl `ls` (list), der den Inhalt eines Verzeichnisses anzeigt: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5lFPHMiwNgr"
      },
      "source": [
        "!ls /content/drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cq7NdlVzK8I"
      },
      "source": [
        "Jedem Colab-Notebook ist auch ein gewisser Cloudspeicher zugeteilt, der auch dann für eine Weile erhalten bleibt, wenn z.B. das Browser-Fenster geschlossen wird. Um nicht andauernd Ihr Google-Drive erneut einbinden zu müssen, können Sie Dateien zwischen Ihrem Google-Drive und diesem temporären Cloudspeicher kopieren.\n",
        "\n",
        "Der Linuxbefehl `mkdir` (make directory) erzeugt ein neues Verzeichnis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xXHr3Dyzxw3"
      },
      "source": [
        "!mkdir bilder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OVn2Qnyz4OO"
      },
      "source": [
        "### 1.0.0 Ein Bild aus Google-Drive kopieren\n",
        "\n",
        "Mit `ls` können wir uns zunächst versichern, dass es auch geklappt hat, und dann mit dem Befehl `cp` (copy) eine Datei aus Ihrem Google-Drive in das neue Verzeichnis kopieren. Passen Sie den Pfad und Dateinamen der folgenden Code-Zelle so an, dass ein Bild aus *Ihrem* GoogleDrive kopiert wird."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX_1UwjL0MLb"
      },
      "source": [
        "!ls\n",
        "!cp /content/drive/My\\ Drive/Images/mein_Profilbild.png bilder/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfWSTBTuycU2"
      },
      "source": [
        "Wenn keine Fehlermeldung aufgetreten ist, wurde die Datei wahrscheinlich in den Ordner `/bilder` kopiert, was Sie entsprechend wir folgt überprüfen können:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF7ZLaA3z3Rw"
      },
      "source": [
        "!ls bilder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZoVWNu_0sdf"
      },
      "source": [
        "Eine weitere Möglichkeit Bilder in das Notebook hineinzubekommen ist das Herunterladen aus dem Internet. Dies kann mit dem Linuxbefehl `wget` erreicht werden. Wir laden nun ein Bild von Wikimedia Commons herunter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAx3E9wDybx7"
      },
      "source": [
        "!wget -O bilder/mondrian.jpg https://upload.wikimedia.org/wikipedia/commons/c/c3/Composition_A_by_Piet_Mondrian_Galleria_Nazionale_d%27Arte_Moderna_e_Contemporanea.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tlvL_PSwjLp"
      },
      "source": [
        "!ls bilder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fxiQ7kN6u2R"
      },
      "source": [
        "### 1.0.1 Ein Bild aus dem Netz kopieren\n",
        "\n",
        "Kopieren Sie nun ein weiteres Bild Ihrer Wahl aus dem Internet in den zuvor erstellten Ordner `/bilder`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C93pJzUVHDTC"
      },
      "source": [
        "# Lösung bitte hier eintragen."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8zbrZD96SwO"
      },
      "source": [
        "**Anmerkungen**\n",
        "\n",
        "- Die Welt der Linuxbefehle wird hier nur am Rande erwähnt. Übersichten finden sich im Internet zuhauf (z.B. [hier](https://www.shellbefehle.de/befehle/) ). Die Verwendung einzelner Befehle lässt sich auch leicht ergooglen, hier zum Beispiel die Anleitung zu [wget](https://wiki.ubuntuusers.de/wget/).\n",
        "- Sobald Sie in einer neuen Sitzung die erste Code-Zelle Ihres Colab-Notebooks ausführen, werden Ihrer Sitzung entsprechende Cloud-Ressourcen in Form einer sogenannten virtuellen Maschine zugeteilt (siehe [Colab-FAQ](https://research.google.com/colaboratory/faq.html) : \"Code is executed in a virtual machine dedicated to your account. Virtual machines are recycled when idle for a while, and have a maximum lifetime enforced by the system.\").\n",
        "- Mit dem Menüpunkt `Runtime->Reset all runtimes...` können Sie bei Bedarf alle bestehenden Sitzungen schließen. Alle auf der virtuellen Maschine gespeicherten Dateien wieder dabei entsprechend gelöscht.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCjPEHn69Fwy"
      },
      "source": [
        "## 1.1 Laden und Darstellen von Bilddateien\n",
        "Im Anmeldeformular haben Sie bereits die Python-Bibliothek `matplotlib` kennengelernt. Wie der Name vermuten lässt, eignet sich diese zum Plotten von mathematischen Grafiken. Es können jedoch auch verschiedene Bilddateien geladen und dargestellt werden. Wir importieren zunächst das Modul `pyplot`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpMEfrw-427H"
      },
      "source": [
        "# das Kürzel plt entspricht der verbreiteten Konvention...\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4u9wjnF-toa"
      },
      "source": [
        "`pyplot` stellt mit `imread` eine Funktion bereit, mit der Bilddateien geladen werden können."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2tKL_F96Obc"
      },
      "source": [
        "# das Bild wird eingelesen\n",
        "img = plt.imread('bilder/mondrian.jpg')\n",
        "print('Der Datentyp des geladenen Bildes: ', type(img))\n",
        "print('Ein Teil der gespeicherten Werte:\\n\\n', img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3jn3zmGWNN3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HF3FN2rFZhS"
      },
      "source": [
        "Das Bild wurde als `numpy.ndarray` geladen. Dabei werden die Farbinformationen der einzelnen Pixel als Gleitkommazahlen im Wertebereich zwischen 0 und 1 repräsentiert (siehe auch optionale Programmieraufgabe im Bewerbungsnotebook).*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOVn4dl4FaPj"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDwursjnADqK"
      },
      "source": [
        "Die ersten Dimensionen des Arrays entsprechen der *Höhe* und *Breite* des Bildes. Die dritte Dimension bilden die Farbkanäle - drei für Rot, Grün und Blau sowie ein vierter für Bilder mit Alpha-Kanal für Transparenz. In jedem einzelnen Feld ist somit der Wert des entsprechenden Farkanals eines Pixels codiert. Entlang der dritten Dimension besteht das Objekt also aus drei gleichgroßen Bildern für die Farben Rot, Grün und Blau. Die Funktion `plt.imshow` kann zur Darstellung solcher Bildobjekte genutzt werden.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqhdny1_BsfC"
      },
      "source": [
        "plt.figure(figsize=(5,5)) # Ein figure-Objekt mit der größe 5x5 wird erstellt.\n",
        "plt.imshow(img) # Das Bilddaten werden dargestellt.\n",
        "plt.axis('off') # Das Achsenkreuz wird nicht mit angezeigt."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECeFGuYl-snj"
      },
      "source": [
        "Hat ein Bildobjekt drei bzw. vier Dimensionen, so wird es von `plt.imshow` als RGB-Bild bzw. RGBA-Bild interpretiert. Wenn nur ein Kanal vorhanden ist, stellt matplotlib das Bild in Pseudofarben dar.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZPyqoiKC8i_"
      },
      "source": [
        "img2 = plt.imread('bilder/mondrian.jpg')\n",
        "print(img2.shape)\n",
        "plt.figure(figsize=(15,10))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1) # Eine Untergrafik wird geöffnet.\n",
        "    plt.imshow(img2[:,:,i], cmap='gray') # Kanal i wird dargestellt.\n",
        "    plt.title('RGB'[i]) # Der i-te Buchstabe von 'RGB' wird als Titel verwendet."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLODn2jIEYWL"
      },
      "source": [
        "Über das optionale Argument `cmap` kann `imshow` ein bestimmtes Farbschema vorgegeben werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tjCduhxDBoK"
      },
      "source": [
        "print(plt.colormaps()) # alle verfügbaren Farbpaletten anzeigen lassen\n",
        "plt.imshow(img2[:,:,0],cmap = 'hot') # irgendeine ausprobieren"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv14kQQaGnEN"
      },
      "source": [
        "### 1.1.0 Eigene Bilddaten plotten\n",
        "Stellen Sie die von Ihnen in den Aufgaben 1.0.0 und 1.0.1 heruntergeladenen Bilder als Farbbild dar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5qN_fUVElNL"
      },
      "source": [
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRJMdq_Dv3ba"
      },
      "source": [
        "### 1.1.1 Einzelne Farbkanäle plotten\n",
        "Erzeugen Sie für eines der Bilder eine Darstellung der einzelnen Kanäle. Verwenden Sie hierfür eine Farbpalette Ihrer Wahl."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kehvXacxv2AV"
      },
      "source": [
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy_wySDwslKD"
      },
      "source": [
        "## 1.2 Faltung\n",
        "\n",
        "Eine wichtige Operation um Bilder zu manipulieren (auch beim maschinellen Lernen) ist die Faltung (engl. convolution). Sie wird uns im Verlauf der Vorlesung noch öfters begegnen.\n",
        "\n",
        "Die untere Animation zeigt die Faltung zweier kontinuierlicher Funktionen. Es wird eine rechteckige Filterfunktion (rot) auf eine ebenso rechteckige Funktion (blau) angewendet. Das Ergebnis dieser Faltung ist eine Dreiecksfunktion (schwarz):\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/6/6a/Convolution_of_box_signal_with_itself2.gif) Quelle: https://de.wikipedia.org/wiki/Faltung_(Mathematik)\n",
        "\n",
        "Der Begriff *Faltung* beschreibt also die Anwengung eines *Filters* oder sogenannten *Kernels* auf Daten - im folgenden Fall auf ein Bild. Bei der zweidimensionalen Faltung ist auch der Filter eine zweidimensionale Matrix, deren Ausmaße kleiner als die des Bildes sind. Dieser Filter wird über das Bild *geschoben*, allerdings nicht kontinuierlich sondern Bildpunkt für Bildpunkt. An jedem Punkt werden die Werte von Bild und Filter multipliziert und aufsummiert. Die so erlangten Werte ergeben dann die Bildpunkte für ein neues, gefiltertes Bild.\n",
        "\n",
        "![Förderprogramm LINK der Stiftung Niedersachsen - Aufgabensammlung 1](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides.gif) Quelle: https://github.com/vdumoulin/conv_arithmetic\n",
        "\n",
        "Die Python-Bibliothek `scipy` beinhaltet neben vielen anderen Funktionen des *Scientific Computing* auch die zweidimensionale Faltung."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO-2aNxqYrNc"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.signal import convolve2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F34qYrQMK8yF"
      },
      "source": [
        "# Um es einfach zu halten, arbeiten wir erstmal mit einem Graustufenbild\n",
        "bw_img = img.mean(axis=2) # Mitteln über Farbkanäle erzeugt ein Graustufenbild."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEF_PfzrZOMZ"
      },
      "source": [
        "Die Art des Filters enscheidet über das Ergebnis der Faltung. \n",
        "\n",
        "Wir definieren zunächst einen Filter, in dem überall die gleiche Zahl steht. Effektiv mittelt dieser Filter alle Pixel in seinem Bereich und erzeugt so ein verwischtes bzw. geglättetes Bild. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_RArAP8ZzQT"
      },
      "source": [
        "# Die Filtergröße bestimmt wie starkt das Bild geglättet wird.\n",
        "filt_size = 9\n",
        "# Erzeugen der Filtermatrix.\n",
        "filt = np.ones((filt_size, filt_size))\n",
        "# Um die Skalierung der Ausgabe unabhängig von der Filtergröße zu machen,\n",
        "# werden die Filterwerte durch ihre Summe geteilt.\n",
        "filt/=filt.sum()\n",
        "# Anwendung des Filters auf das Bild\n",
        "filt_img = convolve2d(bw_img,filt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMOTtcnRMMx-",
        "cellView": "form"
      },
      "source": [
        "#@title Bitte ausführen: Funktion zum Darstellen der Bilder und des Filters\n",
        "def plot_convolution(image, filt, convolution):\n",
        "\n",
        "    plt.figure(figsize = (15,15))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title('Orginalbild')\n",
        "    plt.imshow(image,cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title('Filter')\n",
        "    plt.imshow(filt,cmap= 'gray')\n",
        "    plt.axis('off')\n",
        "    plt.xlim(-10,15)\n",
        "    plt.ylim(-10,15)\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.title('Faltung')\n",
        "    plt.imshow(convolution,cmap = 'gray')\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPhcaEMAMvCM"
      },
      "source": [
        "plot_convolution(bw_img, filt, filt_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxrv_s6Tcs2h"
      },
      "source": [
        "Andere Filterkonfigurationen können zum Beispiel Kanten hervorheben, wie etwa der [Sobel-Operator](https://de.wikipedia.org/wiki/Sobel-Operator):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hR8WeunctFr"
      },
      "source": [
        "# Der Sobel-Operator\n",
        "filt = np.array([[1,0,-1],\n",
        "                 [2,0,-2],\n",
        "                 [1,0,-1]])\n",
        "\n",
        "# Anwendung des Filters auf das Bild\n",
        "filt_img = convolve2d(bw_img,filt)\n",
        "\n",
        "plot_convolution(bw_img, filt, filt_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D8sLRKBg2kB"
      },
      "source": [
        "Wenden Sie nun drei weitere Filter an und versuchen Sie zu verstehen und zu erklären, was diese bewirken.\n",
        "\n",
        "---\n",
        "\n",
        "### 1.2.0 Filter 0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhXgsDNehDei"
      },
      "source": [
        "f1 = np.array([[0,0,0],\n",
        "               [0,1,0],\n",
        "               [0,0,0]])\n",
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTaJVq8t8L0v"
      },
      "source": [
        "### 1.2.1 Filter 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXtFXH2_8GjE"
      },
      "source": [
        "f2 = np.array([[0, -1, 0],\n",
        "               [-1, 5,-1],\n",
        "               [0, -1, 0]])\n",
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSG9vgQs8MgB"
      },
      "source": [
        "### 1.2.2 Filter 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32-njqcE8IE0"
      },
      "source": [
        "f3 = np.array([[1,2, 1],\n",
        "               [2,4,2],\n",
        "               [1,2,1]])/16.\n",
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFpMUHx2HVBq"
      },
      "source": [
        "## 1.3 Manipulation von Bildern mit PIL\n",
        "Der von `plt.imread` zurückgegebene Datentyp `numpy.ndarray` ist für das Rechnen mit Matrizen und die Manipulation von großen Datenmengen ausgelegt und beinhaltet keine spezielle Funktionalität für die Bearbeitung von Bildern. Hierfür gibt es das Paket `PIL` (Python Image Library). In `PIL` ist der Datentyp `Image` implementiert, der eine Menge an bildspezifischer Funktionalität bereitstellt. Der PIL-Datentyp ist dennoch weiterhin kompatibel mit `matplotlib`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWJR4-2mLidu"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "img = Image.open('bilder/mondrian.jpg')\n",
        "img = img.convert('RGB')\n",
        "print(type(img))\n",
        "print(dir(img)) # 'dir' gibt alle Attribute und Methoden eines Objekts zurück"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk4i2HpGOiMN"
      },
      "source": [
        "Transformationen wie Rotation, Größenänderung oder Cropping können einfach erreicht werden. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BytMRLTULlA3"
      },
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "# rotation\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img.rotate(45))\n",
        "# resizing\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(img.resize((100,100)))\n",
        "# grayscale\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(img.crop((100,100,200,300)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcgW7jiSPhgZ"
      },
      "source": [
        "Das Modul `ImageFilter` enthält verschiedene Filtern, die genauso funktionieren wie im vorherigen Abschnitt dargestellt. Mit Filtern können unterschiedliche Aspekte in Bildern hervorgehoben werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gnVCc-RMrKi"
      },
      "source": [
        "from PIL import ImageFilter\n",
        "print(dir(ImageFilter)) # filtertypen anzeigen\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "# verwischen\n",
        "plt.subplot(1,2,1)\n",
        "filt_img = img.filter(ImageFilter.GaussianBlur)\n",
        "plt.imshow(filt_img)\n",
        "# Kanten finden\n",
        "plt.subplot(1,2,2)\n",
        "filt_img = img.filter(ImageFilter.FIND_EDGES)\n",
        "plt.imshow(filt_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2LVPyKnQ7yL"
      },
      "source": [
        "### 1.3.0 Vorgegebene Aufgabe zur Bildmanipulation mit PIL\n",
        "\n",
        "Wählen Sie ein Bild Ihrer Wahl aus, um es mit den Werkzeugen, die `PIL` Ihnen bietet, wie folgt zu bearbeiten:\n",
        "\n",
        "- Trennen Sie das Bild in die jeweiligen Farbkanäle mit Hilfe der Methode `image.split()`.\n",
        "- Wenden Sie unterschiedliche Transformationen auf die einzelnen Farbkanal-Bilder an (Rotation, Translation, Faltung etc.).\n",
        "- Fügen Sie die Farbkanal-Bilder wieder zu einem Bild zusammen mit Hilfe der Methode `image.merge()`.\n",
        "- Stellen Sie das Ergebnis mit `plt.imshow()` dar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNU_3gzDae-v"
      },
      "source": [
        "#Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N06gVw5T-Jq1"
      },
      "source": [
        "### 1.3.1 Freie Aufgabe zur Bildmanipulation mit PIL\n",
        "\n",
        "Wählen Sie ein Bild Ihrer Wahl aus und verändern Sie es mit den Werkzeugen, die `PIL` Ihnen bietet. Probieren Sie verschiedene Filter aus. Lassen Sie Ihrer Fantasie freien Lauf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF1D_qfaAYBt"
      },
      "source": [
        "#Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqz785lkYJqE"
      },
      "source": [
        "## 1.4 Annotierte Bilddaten\n",
        "Für das Trainieren neuronaler Netze werden große Mengen annotierter Daten benötigt. Mittlerweile gibt es eine Reihe von frei verfügbaren Datensätzen mit unterschiedlichen Inhalten. Als Beispiel werden wir hier einen Datensatz namens `Cifar10` herunterladen und inspizieren. Dieser besteht aus ca. 60.000 Bildern mit einer groben Auflösung von lediglich 32x32 Bildpunkten. Die Bilder sind in 10 verschiedene Kategorien unterteilt (gelabelt). Die Daten können direkt von [dieser Website](https://www.cs.toronto.edu/~kriz/cifar.html) heruntergeladen werden.\n",
        "\n",
        "Moderne Deep-Learning-Frameworks wie z.B. [`Keras`](https://keras.io/) stellen jedoch Import-Funktionen für verschiedene Datensätze bereit und ersparen uns somit das Herunterladen gepackter Binärdateien sowie die Auseinandersetzung mit den rohen Datenstrukturen.\n",
        "\n",
        "Wir werden Keras im Verlauf des Kurses noch genauer kennenlernen. Hier begnügen wir uns jedoch zunächst mit dem Modul `datasets`.\n",
        "\n",
        "---\n",
        "\n",
        "**Anmerkungen**\n",
        "\n",
        "- Um den zugehörigen Rechenaufwand gering zu halten, wurde für den Cifar10-Datensatz eine sehr geringe Auflösung gewählt.\n",
        "- Keras ist ein Bestandteil von Googles Deep-Learning-Paket [`Tensorflow`](https://www.tensorflow.org)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMiFPANNZScD"
      },
      "source": [
        "from tensorflow.keras import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ebdok9eKb8"
      },
      "source": [
        "\n",
        "Die Funktion ```help``` gibt uns nähere Informationen über das importierte Modul.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5pALMv0eLGC"
      },
      "source": [
        "help(datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MZf3G3rcY7l"
      },
      "source": [
        "help(datasets.cifar10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQRd9S-6eiP5"
      },
      "source": [
        "Wir benutzen also die Funktion `load_data()`, um die Trainings- und Testdaten auszugeben: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5wcAGwPexq7"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "print(x_train.shape,y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aZ3sFyshaQP"
      },
      "source": [
        "Der Konvention folgend enthalten die mit `x` bezeichneten Variablen jeweils die Eingabedaten und die mit `y` versehenen Variablen die gewünschte Ausgabe, sprich die Annotationen bzw. das Teacher-Signal. Die Annotationsvektoren beinhalten die Zahlen 0-9 für die 10 verschiedenen Klassen. Leider sind die Klassenbezeichnungen nicht enthalten, können aber der ursprünglichen Website entnommen werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnHXExgmiFzK"
      },
      "source": [
        "class_labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doRtFyFux64G"
      },
      "source": [
        "Wir können nun ein Bild für jede Klasse darstellen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j4vhpo9cfQn"
      },
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "for i in range(10):\n",
        "    # Die Funktion np.where gibt die Indices zurück, für die die Bedingung wahr ist.\n",
        "    class_inds = np.where(y_train == i)[0]\n",
        "    # Wir nehmen einfach den ersten.\n",
        "    ind = class_inds[0]\n",
        "    # Ein Achsenkreuz wird erstellt\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.imshow(x_train[ind])\n",
        "    plt.title(class_labels[i])\n",
        "    # Achsenbezeichnungen werden nicht benötigt\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ52CB-n1RKV"
      },
      "source": [
        "### 1.4.0 Der MNIST-Datensatz\n",
        "\n",
        "Laden Sie aus `tensorflow.keras.datasets` den Datensatz `MNIST` herunter und stellen Sie je ein Beispiel für die einzelnen Klassen dar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggzSJF3217TA"
      },
      "source": [
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZZKY23Y16fZ"
      },
      "source": [
        "## 1.5 Bildklassifikation mit vortrainierten Netzwerken\n",
        "Große neuronale Netze zur Bildklassifikation müssen auf riesigen annotierten Datensätzen trainiert werden. Dies ist kostspielig, da es viel Zeit auf teuren Großrechnern in Anspruch nimmt. Die Universität von Stanford richtet jährlich einen Wettbewerb aus, bei dem möglichst gute Klassifizierungsergebnisse auf dem [ImageNet-Datensatz](http://www.image-net.org/) erzielt werden sollen. Viele der Netzwerke, die für diesen Zweck trainiert wurden, sind offen zugänglich und können in dem Modul `keras.applications` geladen werden. \n",
        "\n",
        "Im Folgenden Laden wir das vortrainierte Netzwerk `ResNet50` herunter und wenden es auf einige Bilder an.\n",
        "\n",
        "Da diese Modelle viel Rechenleistung benötigen, ist es wichtig, dass Sie in Ihrem Notebook unter `Runtime->Change Runtime Type` die Option `GPU` (Graphics Processing Unit) oder `TPU` (Tensor Processing Unit) aktivieren. Diese zusätzliche Hardware beschleunigt die Berechnungen von neuronalen Netzen erheblich. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLCxVZzy6ZUT"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "# das Modell wird initialisiert und die gewichte werden heruntergeladen\n",
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWae_bAnGsp6"
      },
      "source": [
        "Wir laden ein weiteres Bild aus den Weiten des Internets herunter, um das ResNet-Modell anschließend darauf anzuwenden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NChdUSrQ_Gp"
      },
      "source": [
        "!wget -O bilder/test.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Benediktinerkloster_St._Johann_retouched.jpg/320px-Benediktinerkloster_St._Johann_retouched.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hUyu8fKGJXu"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image # in Keras eingebaute Bildfunktionalität\n",
        "img_path = 'bilder/test.jpg'\n",
        "# Wir laden das Bild mit der zugehörigen Funktion von Keras. Die Größe des\n",
        "# Bildes muss mit der beim Trainieren verwendeten Bildgröße übereinstimmen.\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I07LpiQ6yCO"
      },
      "source": [
        "Bevor wird das Bild in das Netz \"füttern\" können, muss es in die Form der Daten gebracht werden, mit der das Netz trainiert wurde. Für diese Vorverarbeitung stellt das zugehörige Modul die Funktion `preprocess_input` bereit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8qcjIdk5ahF"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Zs9PNy8GOs"
      },
      "source": [
        "Nun kann das Modell auf das Bild angewendet werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SToDx4u_8OZf"
      },
      "source": [
        "predictions = model.predict(x)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Ot0ghUisth"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zy3cb9H8dAA"
      },
      "source": [
        "Das Modell spuckt eine Matrix mit 1000 Zahlen aus. Diese repräsentieren die Wahrscheinlichkeiten der einzelnen Klassen, auf die das Netzwerk trainiert wurde. Um diese interpretieren zu können, stellt das ResNet-Modul uns die Funktion `decode_predictions` zur Verfügung.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Je9-zrs8cVA"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
        "print('Predicted:', decode_predictions(predictions, top=3)[0])  # Auswahl der drei höchsten Zuordnungen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVK5fAsr-HTp"
      },
      "source": [
        "### 1.5.0 Eigene Vorhersagen mit ResNet50\n",
        "\n",
        "Wenden Sie das ResNet50-Modell auf mindestens drei weitere Bilder unterschiedlicher Art an. Diese können z.B. zu folgenden Kategorien gehören:\n",
        "- natürliche Szene (Foto etc.)\n",
        "- Gemälde (fotorealistisch vs. abstrakt)\n",
        "- Screenshot eines Computerspiels (moderne, aufwändige Grafik vs. Retro-Spiel)\n",
        "\n",
        "Bewerten Sie jeweils kurz das Ergebnis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-iYkO4n6YPc"
      },
      "source": [
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tpJFdKwswPL"
      },
      "source": [
        "## 1.6 Image Style Transfer\n",
        "\n",
        "Die rasante Entwicklung der neuronalen Netze in den letzten Jahren bringt immer wieder überraschende und beeindruckende Ergebnisse hervor. Algorhitmen wie der [Image Style Transfer](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf) (IST) beruhen oft auf zufälligen Entdeckungen, die dann sehr smart weitergedacht und genutzt werden können. Beim IST wird die Tatsache genutzt, dass verschiedene Arten von Information, zum Beispiel *Style* und *Content* eines Bildes an unterschiedlichen Stellen in neuronalen Netzen kodiert werden. Auf diese Thematik werden wir in den folgenden Einheiten noch genauer eingehen.\n",
        "\n",
        "Hier laden wir lediglich eine vorgefertigte Funktion herunter, die den Stil von einem Bild auf ein anderes Bild anwendet.\n",
        "\n",
        "Die Plattform [github](github.com) ist mittlerweile der Standard zum Teilen und Veröffentlichen von OpenSource-Code. Von hier *clonen* wir jetzt das *Repository* `ISTfun`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLCvIQK-s0Od"
      },
      "source": [
        "!git clone https://github.com/insitubytes/ISTfun.git "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hfekTz6EcFN"
      },
      "source": [
        "Das Repository wird in den Workspace geklont und muss manuell zum Pfad hinzugefügt werden, den Python nach Modulen durchsucht.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFyP8bGTl_Ai"
      },
      "source": [
        "!ls bilder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYGzJZi0EnHU"
      },
      "source": [
        "import sys\n",
        "sys.path.append('ISTfun')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZRiexEGrmik"
      },
      "source": [
        "Nun kann das Modul `istfun` importiert werden. Dieses stellt die Funktion `image_style_transfer` bereit:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zck5EJ9ltAmE"
      },
      "source": [
        "import istfun\n",
        "istfun.image_style_transfer?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTAko9e_tJVS"
      },
      "source": [
        "Wir können nun ein beliebiges Bild als \"Content-Bild\" verwenden und im Stil eines anderen darstellen lassen. Dieser Vorgang kann ein paar Minuten in Anspruch nehmen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzHevpcjEomH"
      },
      "source": [
        "content_image = Image.open('bilder/test.jpg')\n",
        "style_image = Image.open('bilder/mondrian.jpg')\n",
        "\n",
        "output_image = istfun.image_style_transfer(content_image,style_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqCWsYEhEvLm"
      },
      "source": [
        "plt.imshow(output_image)\n",
        "_ = plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eupM4cCDuoL0"
      },
      "source": [
        "### 1.6.0 Aufgabe zum Image Style Transfer\n",
        "\n",
        "Wenden Sie den Image-Style-Transfer auf ein Bild Ihrer Wahl an."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1RHj8gHjwY2"
      },
      "source": [
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu2Hts0-u20i"
      },
      "source": [
        "### 1.6.1 Zusatzaufgabe zum Image Style Transfer\n",
        "\n",
        "Wenn Sie zügig mit den Aufgaben fertig geworden sind und noch Zeit haben, laden sie verschiedene Bilder herunter und ordnen Sie diese in einem Raster an, so dass jedes Bild in Kombination mit jedem anderen jeweils einmal als Style- und einmal als Content-Image benutzt wird.\n",
        "\n",
        "Tip: Hierfür benötigen Sie zwei geschachtelte Schleifen und die Funktion `plt.subplot()` zur Darstellung des Rasters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LmbkMgKP-qQ"
      },
      "source": [
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-4c1Ca7Qtqv"
      },
      "source": [
        "![insitubytes](https://drive.google.com/uc?id=1EAJK7AI9tcZRo3VvYq7vEKGxk7vmK2Ff)"
      ]
    }
  ]
}