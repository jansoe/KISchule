{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A4_0_jan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jansoe/KISchule/blob/main/A4_0_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX02S6Aq8OxF"
      },
      "source": [
        "# 4. Generative Netzwerke\n",
        "\n",
        "\n",
        "Sie haben nun schon ein wenig Erfahrung mit neuronalen Netzen in der Bildbearbeitung gesammelt und von den Grundlagen des Perzeptrons bis zum Hacking großer Netzwerke einiges gelernt. Diese Woche wenden wir uns einem weiteren interessanten Themenbereich zu: Den generativen Netzen. \n",
        "\n",
        "Bisher hatten alle unsere Netze eine ähnliche Struktur: Als *Input* wird ein Bild hineingesteckt und als *Output* bekommen wir einen Haufen Zahlen, der die Wahrscheinlichkeiten für verschiedene Klassenzugehörigkeiten kodiert. Im letzten Notebook haben Sie zwar gelernt, wie wir mit Hilfe solcher Netzwerke Bilder generieren können, dies war jedoch eine Art Hack, bei dem die Netze in gewisser Weise zweckentfremdet wurden.\n",
        "\n",
        "Im Notebook A1 haben wir gesehen, dass es sich bei digitalen Bildern im Grunde auch nur um einen Haufen Zahlen handelt. Es spricht also nichts dagegen, dass eine neuronales Netz auch *Bilder* als *Output* generieren könnte.  \n",
        "\n",
        "In diesem Abschnitt lernen Sie zwei Methoden kennen, mit denen Bilder generiert werden können: [*Autoencoder*](https://de.wikipedia.org/wiki/Autoencoder), die über den Umweg einer kompakten Kodierung ein Bild rekonstruieren, und[*Generative Adversarial Networks*](https://de.wikipedia.org/wiki/Generative_Adversarial_Networks) (GANs), bei denen ein *generatives* Netz versucht, ein *diskriminatives* Netz auszutricksen. In diesem ersten Teil zum Thema generative Netzwerke befassen wir uns zunächst mit den Autoencodern.\n",
        "\n",
        "Das Verfahren ist wie gehabt:\n",
        "- Erstellen Sie eine Kopie dieses Notebooks in ihrem Google Drive (vorgeschlagene Umbenennung: \"A4 - Vorname, Nachname\")\n",
        "- Editieren Sie die Text- und Codezellen.\n",
        "- Schicken Sie einen Link zum Kommentieren Ihres Notebook an\n",
        "\n",
        "---\n",
        "\n",
        "**Anmerkungen**\n",
        "\n",
        "- Wie schon in A3 verwenden wir tensorflow in der aktuellen Version 2. Solange diese Version nicht standardmäßig in Colab importiert wird, müssen wir dies explizit angeben:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABcCVouWB9fx"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKgoIQgiDQ0G"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Es lohnt sich zu überprüfen, ob man auch wirklich eine GPU bekommen hat.\n",
        "print(\"Anzahl der zugewiesenen GPUs:\", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc79VlOAOM9B"
      },
      "source": [
        "## 4.0 Autoencoder\n",
        "\n",
        "Der [Autoencoder](https://de.wikipedia.org/wiki/Autoencoder) besteht aus zwei Teilen: einem *Encoder* und einem *Decoder*. Der Encoder bekommt als Input ein Bild und generiert als Output einen *Code*, der eine kompakte Repräsentation wichtiger Merkmale des Inputs darstellt. Dieser *Code* wird dann dem *Decoder* als Input übergeben. Die Aufgabe des Decoders besteht darin, aus dem Code wieder das ursprüngliche Inputbild möglichst gut zu rekonstruieren. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_z4cD2qSKAY"
      },
      "source": [
        "![](data:image/png;base64,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)\n",
        "(Quelle:https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw6-CcDZit1_"
      },
      "source": [
        "Der ursprüngliche Zweck eines Autoencoders ist die Kompression mithilfe einer geeigneten Kodierung. Dieser Code (also die kompakte Repräsentation des Inputs) hat zumeist eine deutlich niedrigere Dimensionalität als das Inputbild. Schafft man es, das Bild aus dem Code zu rekonstruieren, hat man also die im Bild enthaltene relevante Information in einem kompakteren Format gespeichert. Da die Suche nach einer möglichst guten Kodierung dank maschinellen Lernens automatisch passiert, wurde das ganze Autoencoder getauft.\n",
        "\n",
        "Trainiert werden Autoencoder so, dass man für Input und gewünschte Ausgabe jeweils dasselbe Bild präsentiert. Wird der Autoencoder auf einer großen Anzahl von Bildern trainiert, lernt er die in den Bildern enhaltene Struktur und deren Statistik. \n",
        "\n",
        "Wie Ihnen vielleicht schon aufgefallen ist, haben wir es hier mit einem Beispiel von *self-supervised learning* zu tun. Es werden also nicht, wie beim Training von Klassifikationsnetzwerken, annotierte Daten benötigt sondern einfach nur die Bilder, die gleichzeitig Input und gewünschte Ausgabe (Teacher-Signal) sind.\n",
        "\n",
        "Neben der Komprimierung ergibt sich aus der Art wie Autoencoder trainiert werden auch die Möglichkeit, den Decoder getrennt zu verwenden. Ebenso wie der Encoder muss der Decoder die inhärente Struktur der Daten lernen, um die Bilder möglichst gut rekonstruieren zu können. Wir können den Decoder also dazu benutzen, neue Bilder zu generieren. \n",
        "\n",
        "Im Folgenden nehmen wir uns wieder den guten alten MNIST-Datensatz vor, um die Funktionsweise des Autoencoders kennenzulernen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOH3x1tXljGx"
      },
      "source": [
        "### 4.0.0 Laden des MNIST-Datensatzes\n",
        "\n",
        "Viele der folgenden Schritte kennen Sie bereits. Wir importieren einige Bibliotheken und laden mit Hilfe von `Keras` den MNIST-Datensatz herunter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6sSUrDuDXkX"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qZ4SAPRDacS"
      },
      "source": [
        "# Herunterladen des Datensatzes\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UX1eYAnDeic"
      },
      "source": [
        "# Hinzufügen einer weiteren Dimension für Convolutional Networks\n",
        "train_images = train_images[:,:,:,np.newaxis].astype('float32')\n",
        "# Und Skalierung auf den Bereich [0,1]\n",
        "train_images_01 = train_images / 255.\n",
        "\n",
        "test_images = test_images[:,:,:,np.newaxis]\n",
        "test_images_01 = test_images / 255.\n",
        "\n",
        "train_images_01.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q38R8YSm39j"
      },
      "source": [
        "### 4.0.1 Encoder und Decoder\n",
        "\n",
        "Wie bereits erwähnt, besteht der Autoencoder aus einem *Encoder* und einem *Decoder*, die wir hier als getrennte Netzwerkteile implementieren. Der *Code*, also die Schicht, die die Ausgabe der Encoders und die Eingabe des Decoders darstellt, wird im Fachjargon oft *latente Variable* genannt, da sie *unter der Oberfläche* liegt und nicht direkt einsehbar ist. \n",
        "\n",
        "Wir müssen für unsere *latente Variable* eine Dimensionalität festlegen, also die Anzahl der Elemente/units, aus der der Code bestehen soll. Die MNIST-Ziffern haben eine Auflösung von 28x28 Pixel. Die in den Bildern enthaltene Information beschränkt sich aber auf eine von zehn Ziffern. Es ist also davon auszugehen, dass die Information sehr stark komprimiert werden kann. Wir wählen entsprechend einen Code mit acht Kanälen.\n",
        "\n",
        "Bei der Konstruktion des Encoders gehen wir ähnlich vor wie bei den Klassifikationsnetzwerken in Notebook A2. Wir schalten zwei Faltungsschichten hintereinander. Anstelle der zehn Zellen für die Klassifikation der Ziffern wählen wir als Ausgabe diesmal entsprechend unserem Code eine Schicht mit acht Zellen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh0jExCRNysK"
      },
      "source": [
        "latent_dim = 8\n",
        "\n",
        "encoder = tf.keras.Sequential(\n",
        "    name='encoder',\n",
        "    layers = [\n",
        "        layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "        layers.Conv2D(filters=32, kernel_size=3, strides=2, activation='relu'),\n",
        "        layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(latent_dim),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWjTrgZLo28K"
      },
      "source": [
        "Der Decoder soll nun die acht Kanäle der Ausgabeschicht des Encoders wieder in ein 28x28-Pixelbild umwandeln. Wir können uns den Decoder also als eine Art *umgedrehten* Encoder vorstellen. Hierfür bietet sich die in `Keras` implementierte Klasse `Conv2DTranspose` an, die die entsprechende Umkehroperation einer `Conv2D`-Schicht umsetzt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPxcbAdVhj2-"
      },
      "source": [
        "decoder = tf.keras.Sequential(\n",
        "    name = 'decoder', \n",
        "    layers = [\n",
        "        layers.InputLayer(input_shape=(latent_dim,)),\n",
        "        layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
        "        layers.Reshape(target_shape=(7, 7, 32)),\n",
        "        layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding=\"same\", activation='relu'),\n",
        "        layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding=\"same\", activation='relu'),\n",
        "        layers.Conv2DTranspose(filters=1,  kernel_size=3, strides=1, padding=\"same\", activation='sigmoid'),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-jWvPYjpjcA"
      },
      "source": [
        "Wir können die beiden Netzwerke jetzt verbinden, indem wir ein Modell generieren, dessen *Input* der input des *Encoders* ist, während der *Output* der Output des *Decoders* ist,  dem zuvor der *Output* des Encoders (also der *Code*) als *Input* gegeben wurde. Das klingt jetzt komplizierter als es ist, und kann am besten grafisch aufgefasst werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib91KPB3hkJj"
      },
      "source": [
        "# autoencoder = tf.keras.Sequential([encoder, decoder])\n",
        "autoencoder = tf.keras.Model(inputs=encoder.input, outputs=decoder(encoder.output))\n",
        "# encoder_model = encoder(encoder.input)  # kleiner Hack, um einen besseren Graphen zu bekommen\n",
        "# autoencoder = tf.keras.Model(inputs=encoder.input, outputs=decoder(encoder_model))\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUk1ExpILaca"
      },
      "source": [
        "tf.keras.utils.plot_model(autoencoder, show_shapes=True, dpi=70, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1zzu08sqXF2"
      },
      "source": [
        "Unser untrainiertes Modell ist bislang lediglich mit Zufallszahlen gefüllt und generiert daher aus den Inputbildern einen Ameisenkrieg der Größe 28x28."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO6mkohB7dci"
      },
      "source": [
        "decoded_imgs = autoencoder.predict(test_images_01)\n",
        "\n",
        "n_plot = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n_plot):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n_plot, i+1)\n",
        "    plt.imshow(test_images_01[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n_plot, i+n_plot+1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVAQoyg-quxV"
      },
      "source": [
        "### 4.0.2 Trainieren des Modells\n",
        "\n",
        "Wir trainieren jetzt den Autoencoder anhand der Ziffernbilder. Beachten Sie, dass `x` und `y` in der `fit`-Funktion als Trainingsdaten *und* gewünschte Ausgabe *dieselbe* Variable sind, da der Autoencoder diese rekonstrukieren soll."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYuQOgY5hkFB"
      },
      "source": [
        "autoencoder.fit(\n",
        "    x = train_images_01, \n",
        "    y = train_images_01,\n",
        "    epochs=40,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    validation_data=(test_images_01, test_images_01)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3gKYjYVs1CH"
      },
      "source": [
        "Jetzt können wir das Netzwerk erneut Output zu den Testdaten erzeugen lassen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNdJQV7uhj_7"
      },
      "source": [
        "encoded_imgs = encoder.predict(test_images_01)\n",
        "de_encoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(30, 8))\n",
        "for i in range(n):\n",
        "\n",
        "    # display original\n",
        "    ax = plt.subplot(3, n, i+1)\n",
        "    plt.imshow(test_images_01[i].reshape(28, 28))\n",
        "    plt.axis('off')\n",
        "\n",
        "    # encodint original\n",
        "    ax = plt.subplot(3, n, n+i+1)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 2), cmap=plt.cm.Spectral, vmin=-10, vmax=10)\n",
        "    plt.xlim((-5, 9))\n",
        "    plt.ylim((-5, 9))\n",
        "    plt.axis('off')\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(3, n, 2*n+i+1)\n",
        "    plt.imshow(de_encoded_imgs[i].reshape(28, 28))\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2MkL6Lyo9ZP"
      },
      "source": [
        "Wie wir sehen, erzeugt das Modell Ziffern, die dem Input sehr ähnlich sind. In der Mitte der Darstellung sehen sie den jeweils zugehörigen *Code*. Es ist wichtig sich vor Augen zu führen, dass sämtliche Information im Autoencoder durch diesen *Flaschenhals* fließen muss. Das heisst, die Outputbilder werden aus dem achtstelligen Code generiert und nicht aus dem Inputbild."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqsso7dFtkfr"
      },
      "source": [
        "### 4.0.3 Der Decoder als generatives Modell\n",
        "\n",
        "Da der Decoder nur auf Basis der *latent variable* arbeitet, können wir ihn auch isoliert benutzen. Wir können auf Basis von *Codes* mit beliebigen Werten zugehörige Bilder generieren lassen. \n",
        "\n",
        "Versuchen wir zunächst einen zufälligen Code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "572Eq8JKBnY3"
      },
      "source": [
        "np.random.seed(44)\n",
        "random_encoding = (np.random.rand(latent_dim)-0.5)*10\n",
        "random_img = decoder.predict(random_encoding[np.newaxis]).reshape((28,28))\n",
        "\n",
        "plt.figure(figsize=(5,10))\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(random_encoding.reshape((4,2)),  cmap=plt.cm.Spectral, vmin=-10, vmax=10)\n",
        "plt.axis('off')\n",
        "plt.subplot(2,1,2)\n",
        "plt.imshow(random_img)\n",
        "_ = plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3KZU7CrwGxj"
      },
      "source": [
        "Der *latente Raum*, also alle möglichen Kombinationen von Zahlen, die der Code abdecken kann, ist riesig, und nur in bestimmten Bereichen haben sich durch das Training *Cluster* gebildet, in denen die einzelnen Ziffern abgebildet sind. Wir sehen aber, dass auch ein zufällig gewählter Code ein Gebilde hervorbringt, dass die gundlegende Struktur einer handgeschriebenen Ziffer besitzt. \n",
        "\n",
        "Wir können gezielt einen Punkt im Code-Raum aussuchen, indem wir eine Zahl hineingeben. Wählen wir anschließend eine zufällige Veränderungsrichtung, und addieren diese mit immer größer werdenden Gewichtungen auf den Code, so sieht das dekodierte Bild zunächst noch aus wie die ursprüngliche Zahl. Doch je mehr wir uns vom ursprünglichen Code entfernen, desto mehr verschwindet unsere Zahl."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTmeIWPvxFHE"
      },
      "source": [
        "code = encoder.predict(test_images_01[0][None,:,:,:])\n",
        "direction = np.random.randn(*code.shape)\n",
        "displacements = [0,1,2,4,8,16]\n",
        "plt.figure(figsize=(12,10))\n",
        "for i,d in enumerate(displacements):\n",
        "    plt.subplot(1,len(displacements),i+1)\n",
        "    img = decoder.predict(code+direction*d)\n",
        "    _ = plt.imshow(img.squeeze())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC2biQM3zVNh"
      },
      "source": [
        "Wir haben es bei unserem Code also mit einem *kontinuierlichen* Raum zu tun, in dem jeder Punkt uns ein Ergebnis gibt und nahe beieinanderliegende Punkte ähnliche Bilder hervorbringen. \n",
        "\n",
        "Wir können zum Beispiel auch ein *Morphing* zwischen zwei Zahlen generieren, in dem wir uns im Code-Raum von einer Zahl zur nächsten bewegen und unterwegs einige Bilder generieren:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2c7UVFF5h8S"
      },
      "source": [
        "start_img_number = 1\n",
        "end_img_number = 4\n",
        "morph_steps = 10\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "for i in range(morph_steps):\n",
        "    # Gewichtung des Endbildes gegenüber des Anfangsbildes\n",
        "    alpha = i /(morph_steps-1)\n",
        "    # \"gemorphter\" Code\n",
        "    morphed = (1-alpha) * encoded_imgs[start_img_number] + alpha * encoded_imgs[end_img_number]\n",
        "    decoded = decoder.predict(morphed[np.newaxis]).reshape((28,28))\n",
        "\n",
        "    plt.subplot(2,morph_steps,i+1)\n",
        "    plt.imshow(morphed.reshape((4,2)), cmap=plt.cm.Spectral, vmin=-10, vmax=10)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(2,morph_steps,morph_steps+i+1)\n",
        "    plt.imshow(decoded)\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVrcjdeV0R7c"
      },
      "source": [
        "### 4.0.4 Aufgabe: Addition von Codes\n",
        "- Generieren Sie den *Code* für zwei Zahlen aus dem Testdatensatz.\n",
        "- Stellen Sie die beiden Originalzahlen dar.\n",
        "- Addieren Sie nun die beiden *Codes* und generieren Sie für das Ergebnis ein Bild mit dem Decoder.\n",
        "- Stellen Sie das Ergebnis dar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPf3Z_kn5iK8"
      },
      "source": [
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo4zQ1RMb404"
      },
      "source": [
        "### 4.0.4 Aufgabe: Subtraktion von Codes\n",
        "Verfahren Sie wie in Aufgabe 4.0.4. Verwenden Sie jedoch anstelle der Addition die Differenz der beiden Codes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8DDCXVtceAd"
      },
      "source": [
        "# Lösung:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I37No5ZlXUa"
      },
      "source": [
        "![insitubytes](https://drive.google.com/uc?id=1EAJK7AI9tcZRo3VvYq7vEKGxk7vmK2Ff)"
      ]
    }
  ]
}